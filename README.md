This project is a Hand Sign Language Detection System designed to recognize American Sign Language (ASL) gestures in real time. It uses a Convolutional Neural Network (CNN) model built with TensorFlow and Keras to accurately interpret hand signs captured through a webcam. The system leverages OpenCV and MediaPipe for efficient image capture and processing, enabling users to interact with the application via a Streamlit web interface. This project aims to enhance communication for the deaf and hard of hearing by providing a tool that translates sign language into text. The repository includes all necessary code and instructions to set up and run the application.
